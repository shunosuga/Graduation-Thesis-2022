{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(U_Net_Encoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
    "            \n",
    "        self.pool1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2, groups=2)\n",
    "           \n",
    "        self.pool2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "           \n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "           \n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "           \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "        )\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        \n",
    "        self.fc8 = nn.Linear(4096, 1000)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):       \n",
    "        conv1 = self.conv1(x)        # (96, 55, 55)\n",
    "        x = self.relu(conv1)\n",
    "\n",
    "        x = self.pool1(x)            # (96, 27, 27)\n",
    "    \n",
    "        conv2 = self.conv2(x)        # (256, 27, 27)\n",
    "        x = self.relu(conv2)\n",
    "        \n",
    "        x = self.pool2(x)            # (256, 13, 13)\n",
    "\n",
    "        conv3 = self.conv3(x)        # (384, 13, 13)\n",
    "        x = self.relu(conv3)\n",
    "     \n",
    "        conv4 = self.conv4(x)        # (384, 13, 13)\n",
    "        x = self.relu(conv4)\n",
    "\n",
    "        conv5 = self.conv5(x)        # (256, 13, 13)\n",
    "        x = self.relu(conv5)\n",
    "\n",
    "        x = self.pool3(x)            # (256, 6, 6)\n",
    "\n",
    "        fc6 = self.fc6(x)            # (4096)\n",
    "        x = self.relu(fc6)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        fc7 = self.fc7(x)            # (4096)\n",
    "        x = self.relu(fc7)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        fc8 = self.fc8(x)            # (1000)\n",
    "\n",
    "        return conv1, conv2, conv3, conv4, conv5, fc6, fc7, fc8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net_Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(U_Net_Decoder, self).__init__()\n",
    "\n",
    "        self.rfc8 = nn.Linear(1000, 4096)\n",
    "        \n",
    "        self.rfc7 = nn.Linear(8192, 4096)\n",
    "        \n",
    "        self.rfc6 = nn.Linear(8192, 256*6*6)\n",
    "        \n",
    "        self.rpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=2)\n",
    "        self.rconv5 = nn.ConvTranspose2d(in_channels=512, out_channels=384, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        \n",
    "        self.rconv4 = nn.ConvTranspose2d(in_channels=768, out_channels=384, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        \n",
    "        self.rconv3 = nn.ConvTranspose2d(in_channels=768, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.rpool2 = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=2)\n",
    "        self.rconv2 = nn.ConvTranspose2d(in_channels=512, out_channels=96, kernel_size=5, stride=1, padding=2, groups=2)\n",
    "        \n",
    "        self.rpool1 = nn.ConvTranspose2d(in_channels=96, out_channels=96, kernel_size=3, stride=2)\n",
    "\n",
    "        self.rconv1 = nn.ConvTranspose2d(in_channels=192, out_channels=3, kernel_size=11, stride=4, padding=0)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, conv1, conv2, conv3, conv4, conv5, fc6, fc7, fc8):\n",
    "\n",
    "        x = self.rfc8(fc8)                # (4096)\n",
    "        x = torch.cat((x, fc7), dim=1)    # (8192)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.rfc7(x)                  # (4096)\n",
    "        x = torch.cat((x, fc6), dim=1)    # (8192)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.rfc6(x)                  # (256*6*6)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 256, 6, 6)         # (256, 6, 6)\n",
    "\n",
    "        x = self.rpool3(x)                # (256, 13, 13)\n",
    "        x = torch.cat((x, conv5), dim=1)  # (512, 13, 13)\n",
    "\n",
    "        x = self.rconv5(x)                # (384, 13, 13)\n",
    "        x = torch.cat((x, conv4), dim=1)  # (768, 13, 13)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.rconv4(x)                # (384, 13, 13)\n",
    "        x = torch.cat((x, conv3), dim=1)  # (768, 13, 13)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.rconv3(x)                # (256, 13, 13)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.rpool2(x)                # (256, 27, 27)\n",
    "        x = torch.cat((x, conv2), dim=1)  # (512, 27, 27)\n",
    "\n",
    "        x = self.rconv2(x)                # (96, 27, 27)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.rpool1(x)                # (96, 55, 55)\n",
    "        x = torch.cat((x, conv1), dim=1)  # (192, 55, 55)\n",
    "\n",
    "        x = self.rconv1(x)                # (3, 227, 227)\n",
    "        x = self.sigmoid(x)      \n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, x_recon):\n",
    "\n",
    "        loss = self.loss_func(x, x_recon)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/shunosuga/data/model/u_net/epoch_10'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = U_Net_Encoder().to(device)\n",
    "decoder = U_Net_Decoder().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load(os.path.join(model_dir, 'encoder_10')))\n",
    "decoder.load_state_dict(torch.load(os.path.join(model_dir, 'decoder_10')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def img_preprocess(img, img_mean=np.array([0.485, 0.456, 0.406], dtype=np.float),\n",
    "                   img_std=np.array([0.229, 0.224, 0.225], dtype=np.float), norm=255):\n",
    "    '''convert to Pytorch's input image layout'''\n",
    "    img = img / norm\n",
    "    image = np.float32(np.transpose(img, (2, 0, 1)) - np.reshape(img_mean, (3, 1, 1))) / np.reshape(img_std, (3, 1, 1))\n",
    "    return image\n",
    "\n",
    "def normalized_img(img):\n",
    "    '''Normalize the image.\n",
    "    Map the minimum pixel to 0; map the maximum pixel to 255.\n",
    "    Convert the pixels to be int\n",
    "    '''\n",
    "    img = img - img.min()\n",
    "    if img.max() > 0:\n",
    "        img = img * (255.0 / img.max())\n",
    "    img = np.uint8(img)\n",
    "    return img\n",
    "\n",
    "def get_cnn_features(model, input, extract_feat_list):\n",
    "    net = copy.deepcopy(model)\n",
    "    outputs = []\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        outputs.append(output.clone())\n",
    "\n",
    "    # run the code in exec_code\n",
    "    for exec_str in extract_feat_list:\n",
    "        exec(\"net.\"+exec_str+\".register_forward_hook(hook)\")\n",
    "    outputs = []\n",
    "    _ = net(input)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = np.random.randint(0, 256, [227,227,3])\n",
    "plt.imshow(random_input)\n",
    "random_norm = (random_input / 255).transpose(2, 0, 1)\n",
    "img_input = torch.Tensor(random_norm[np.newaxis]).to(device)\n",
    "\n",
    "conv1, conv2, conv3, conv4, conv5, fc6, fc7, fc8 = encoder(img_input)\n",
    "print(conv1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#対象にするチャンネル\n",
    "channel =  54\n",
    "#対象にする位置\n",
    "w, h = 28, 28\n",
    "\n",
    "rand_list = []\n",
    "value_list = []\n",
    "iter_num = 10000\n",
    "\n",
    "for i in range(iter_num):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{i}回目\")\n",
    "    # ランダム画像を作成\n",
    "    random_input = np.random.randint(0, 256, [227,227,3]) / 255\n",
    "    # 前処理\n",
    "    random_norm = (random_input).transpose(2, 0, 1)\n",
    "    # Tensor型に変換\n",
    "    img_input = torch.Tensor(random_norm[np.newaxis]).to(device)\n",
    "    #活動値の取得\n",
    "    conv1, conv2, conv3, conv4, conv5, fc6, fc7, fc8 = encoder(img_input)\n",
    "    #指定の位置の活動値を取得\n",
    "    act_value = conv1[0, channel, w, h].to('cpu').detach().numpy()\n",
    "    #ランダム画像を保存\n",
    "    rand_list.append(random_input)\n",
    "    #活動値を保存\n",
    "    value_list.append(act_value)\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_img = np.zeros([227,227,3])\n",
    "for i in range(len(rand_list)):\n",
    "    rc_img +=  value_list[i] * rand_list[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_img_out = np.array(rc_img_out, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rc_img_out)\n",
    "plt.show()\n",
    "# 拡大\n",
    "norm_ = rc_img_out[114 -10+4: 114 + 10+3, 114 - 10+4: 114 + 10+3]\n",
    "plt.imshow(norm_)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc778d4ba8bf4c7cf8b5578a526f983b5f0c4aa89cc411f87dfae3cc8028cbac"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('py37': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
